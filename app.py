import streamlit as st
import cv2
import numpy as np
import imutils
from imutils.perspective import four_point_transform
from pyzbar.pyzbar import decode
from PIL import Image

# --- ‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏© A5 (148mm x 210mm) ---
# ‡πÉ‡∏ä‡πâ 10 ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ï‡πà‡∏≠ 1 ‡∏°‡∏°.
W_A5, H_A5 = 1480, 2100 

class OMRScanner:
    def __init__(self):
        self.debug_images = {}

    def preprocess(self, image):
        """1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏Ç‡∏≠‡∏ö"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # ‡πÉ‡∏ä‡πâ CLAHE ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏∂‡∏á Contrast
        clahe = cv2.createCLAHE(clipLimit=3.0, tile_grid_size=(8, 8))
        enhanced = clahe.apply(gray)
        # ‡πÄ‡∏ö‡∏•‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Noise ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
        self.debug_images['1. Grayscale (Enhanced)'] = enhanced
        return enhanced

    def detect_corners_robust(self, processed_img, original_img):
        """2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Corner Marks 4 ‡∏°‡∏∏‡∏° ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥"""
        # ‡πÉ‡∏ä‡πâ Threshold ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥‡∏™‡∏ô‡∏¥‡∏ó
        _, thresh = cv2.threshold(processed_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        self.debug_images['2. Threshold (For Corner Detection)'] = thresh
        
        # ‡∏´‡∏≤ Contours ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cnts = imutils.grab_contours(cnts)
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏®‡∏©‡∏ù‡∏∏‡πà‡∏ô)
        candidates = []
        for c in cnts:
            area = cv2.contourArea(c)
            if area > 100: # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ 100 px
                M = cv2.moments(c)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    candidates.append((cX, cY, area))
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 4 ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        candidates = sorted(candidates, key=lambda x: x[2], reverse=True)[:4]
        
        # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏à‡∏≠‡∏•‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û Original ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ User ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
        debug_points_img = original_img.copy()
        pts = []
        for (x, y, a) in candidates:
            cv2.circle(debug_points_img, (x, y), 20, (0, 255, 0), -1) # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
            pts.append([x, y])
        
        self.debug_images['3. Detected Corner Points'] = debug_points_img
        
        if len(pts) < 4:
            return None, f"‡∏û‡∏ö Corner Marks ‡πÄ‡∏û‡∏µ‡∏¢‡∏á {len(pts)} ‡∏à‡∏∏‡∏î (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏™‡∏á‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á)"
        
        # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Warp
        pts = np.array(pts, dtype="float32")
        try:
            warped = four_point_transform(original_img, pts)
            warped = cv2.resize(warped, (W_A5, H_A5))
            self.debug_images['4. Warped Result'] = warped.copy()
            return warped, None
        except Exception as e:
            return None, f"Warping Failed: {str(e)}"

    def get_omr_data(self, warped):
        """3. ‡∏™‡πÅ‡∏Å‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (QR & OMR)"""
        # ‡∏≠‡πà‡∏≤‡∏ô QR Code ‡∏°‡∏∏‡∏°‡∏Ç‡∏ß‡∏≤‡∏ö‡∏ô
        roi_qr = warped[0:500, 800:1480]
        qr_data = decode(roi_qr)
        qr_str = qr_data[0].data.decode('utf-8') if qr_data else "‡πÑ‡∏°‡πà‡∏û‡∏ö QR Code"
        
        # --- Logic ‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏à‡∏≥‡∏•‡∏≠‡∏á) ---
        # ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏™‡πÅ‡∏Å‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
        return qr_str, "000", "001"

# --- Streamlit UI ---
st.set_page_config(page_title="OMR Robust Warp", layout="wide")
st.title("üî≠ OMR Answer Sheet Processor (Robust Warp Edition)")

uploaded_file = st.file_uploader("Upload Answersheet Image", type=['jpg', 'jpeg', 'png'])

if uploaded_file:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, 1)
    
    scanner = OMRScanner()
    processed = scanner.preprocess(image)
    warped, error = scanner.detect_corners_robust(processed, image)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("üõ† Debugging Visuals")
        if error:
            st.error(error)
            st.image(scanner.debug_images.get('3. Detected Corner Points', image), caption="‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô")
            st.warning("‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ß‡∏≤‡∏á‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡πÇ‡∏ï‡πä‡∏∞‡∏™‡∏µ‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡πÇ‡∏ï‡πä‡∏∞‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°) ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏™‡∏á‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß‡∏°‡∏∏‡∏°")
        else:
            view = st.selectbox("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:", list(scanner.debug_images.keys()))
            st.image(scanner.debug_images[view], channels="BGR" if "Warped" in view or "Detected" in view else "RGB")

    with col2:
        if not error:
            st.subheader("üìä Extraction Results")
            qr_val, book_val, set_val = scanner.get_omr_data(warped)
            st.metric("QR Code ID", qr_val)
            st.write(f"**BookCode:** {book_val} | **SetCode:** {set_val}")
            
            st.info("üí° ‡∏´‡∏≤‡∏Å‡∏†‡∏≤‡∏û Warp ‡∏ï‡∏£‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏û‡∏µ‡πà‡∏ö‡∏∏‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡∏û‡∏¥‡∏Å‡∏±‡∏î OMR ‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô Module ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö")
